---
title: "pre_lab_02.Rmd"
author: "Derek Willis"
date: "2023-01-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Points to hit

1.  Review of first lab and questions/problems.
2.  Review GitHub
3.  Demonstration of filtering, dates and mutate.

### Task 1: Load libraries

**Task** Run the following code in the gray-colored codeblock below -- not in the console -- to load the tidyverse library. To run the code, click the little green play button (left facing arrow) at the top right of the codeblock. In Rmarkdown data notebooks, we write code inside of codeblocks, and explanatory text in the white area outside of it.

```{r}
# turn off sci notation
options(scipen=999)
library(tidyverse)
library(lubridate) # look up lubridate and describe its uses in your reference notebook
```

### Task 2: Load data

**Task** Load the UMD courses data by running the following codeblock. NOTE: it's now located in a `data` folder.

```{r}
umd_courses <- read_rds("data/umd_courses.rds")
```

### Task 3: Glimpse data

**Task** Run the following codeblock to use head(), summary(), colnames() and glimpse() to get a sense of the data, some of the values in each field/variable/column, and the data types of each field/variable/column. Add a description of what these do to your reference notebook.

```{r}
head(umd_courses)
summary(umd_courses)
colnames(umd_courses)
glimpse(umd_courses)
```

## Filter and Select

More often than not, we have more data than we want. Sometimes we need to be rid of that data. In the tidyverse, there's two ways to go about this: filtering and selecting.

**Filtering creates a subset of the data based on criteria**. All records where the seats are greater than 14. All records where the department is "Journalism". Something like that. **Filtering works with rows -- when we filter, we get fewer rows back than we start with.**

**Selecting simply returns only the fields named**. So if you only want to see department and course ID, you select those fields. When you look at your data again, you'll have two columns. If you try to use one of your columns that you had before you used select, you'll get an error. **Selecting works with columns. You will have the same number of records when you are done, but fewer columns of data to work with.**

### Task 4: Filter by one column

**Task** Run the following code to limit our courses to the Journalism school.

```{r}
journalism_courses <- umd_courses |> filter(department == "Journalism")

head(journalism_courses)
```

And just like that, we have just Journalism results, which we can verify looking at the head, the first six rows. We also could filter by a numeric column like `term`, so we could see just courses in 2023:

**Task** Run the following code to limit our courses to those in terms in 2023:

```{r}
courses_2023 <- umd_courses |> filter(term > 202300)

head(courses_2023)
```

### Task 5: Select

We also have more data than we might want. For example, we may only want to work with the course id and title.

To simplify our dataset, we can use select.

**Task** Run the following code to select only certain columns and answer the question below.

```{r}
selected_journalism_courses <- journalism_courses |> select(id, title)

head(selected_journalism_courses)
```

And now we only have two columns of data for whatever analysis we might want to do.

Notice that we made a new variable to hold the result. Why is that important?

**Answer**

### Task 6: Combining filters

So let's say we wanted to see all the courses in the Theatre department with at least 15 seats. We can do this a number of ways. The first is we can chain together a whole lot of filters.

**Task** Run the following code

```{r}
theatre_seats_15 <- umd_courses |> filter(department == "Theatre") |> filter(seats >= 15)

nrow(theatre_seats_15)
```

That gives us 213 records But that's repetitive, no? We can do better using a single filter and boolean operators -- AND and OR. In this case, AND is `&` and OR is `|`.

**Task** Run the following code

```{r}
and_theatre_seats_15 <- umd_courses |> filter(department == "Theatre" & seats >= 15)

nrow(and_theatre_seats_15)
```

So AND gives us the same answer we got before. What does using the OR operator give us?

**Task** Run the following code and put the number of results below.

```{r}
and_theatre_seats_15 <- umd_courses |> filter(department == "Theatre" | seats >= 15)

nrow(and_theatre_seats_15)
```

**Answer**

When it comes to filters, OR is additive; AND is restrictive.

### Task 7: Filter on partial match

Sometimes you need to find rows that contain a certain pattern rather than an exact match - like if you're looking for all of the courses with "Shakespeare" in the title. There are several ways to do this using R, but one way is to use the function `str_detect`, which stands for "string detect". You use it inside a `filter` by supplying the column and the pattern you want to match, like so:

**Task** Run the following code

```{r}
umd_courses |> 
  filter(str_detect(title, "Shakespeare"))
```

The latest version of the tidyverse also has a function called `str_like` which uses the wildcard search operator % to do partial matching.

A general tip about using filter: it's easier to work your way towards the filter syntax you need rather than try and write it once and trust the result. Each time you modify your filter, check the results to see if they make sense. This adds a little time to your process but you'll thank yourself for doing it because it helps avoid mistakes. Note that whatever you're trying to match using `filter` - whether an exact match or a partial one - R is case-sensitive by default. Go back and try the previous block, changing the pattern to "shakespeare" to see this.

## Dates

The key to working with dates is that R needs to know that the column containing the date has a datatype of date (or datetime for timestamps). Regular R will guess, and the tidyverse will make a better guess.

Let's start with a dataset of campaign expenses from Maryland political committees:

```{r}
maryland_expenses <- read_csv("data/maryland_expenses.csv")

head(maryland_expenses)
```

Take a look at that first column, expenditure_date. It *looks* like a date, but see the `<chr` right below the column name? That means R thinks it's actually a character column. What we need to do is make it into an actual date column, which lubridate is very good at doing. It has a variety of functions that match the format of the data you have. In this case, the current format is `m/d/y`, and the lubridate function is called `mdy` that we can use with mutate:

### Task 8: Turning a character date into a real date

**Task** Run the following code and describe the change in the expenditure_date column.

```{r}
maryland_expenses <- maryland_expenses |> mutate(expenditure_date=mdy(expenditure_date))

head(maryland_expenses)
```

**Answer:**

Lubridate has functions for basically any type of character date format: mdy, ymd, even datetimes like ymd_hms.

That's less code and less weirdness, so that's good.

But to get clean data, I've installed a library and created a new field so I can now start to work with my dates. That seems like a lot, but don't think your data will always be perfect and you won't have to do these things.

Still, there's got to be a better way. And there is.

Fortunately, `readr` anticipates some date formatting and can automatically handle many of these issues (indeed it uses lubridate under the hood). When you are importing a CSV file, be sure to use `read_csv`, not `read.csv`.

### Task 9: Creating a new date column from existing dates using mutate

But you're not done with lubridate yet. It has some interesting pieces parts we'll use elsewhere.

For example, in spreadsheets you can extract portions of dates - a month, day or year - with formulas. You can do the same in R with lubridate. Let's say we wanted to add up the total amount spent in each month in our Maryland expenses data.

We could use formatting to create a Month field but that would group all the Aprils ever together. We could create a year and a month together, but that would give us an invalid date object and that would create problems later. Lubridate has something called a floor date that we can use.

So to follow along here, we're going to use a new function, `mutate`, to create a month field, group by to lump them together, summarize to count them up and arrange to order them. We're just chaining things together. Mutate is the key here because it allows us to create a new column from existing data.

**Task** Run the following code

```{r}
maryland_expenses |>
  mutate(month = floor_date(expenditure_date, "month")) |>
  group_by(month) |>
  summarise(total_amount = sum(amount)) |>
  arrange(desc(total_amount))
```

So the month of June 2022 had the most expenditures by far in this data.

Describe the values in the new `month` column - what do you think is going on there?

**Answer**

### Task 10: Mutate

Often the data you have will prompt questions that it doesn't immediately answer. Election results, for example, have raw vote totals but we often don't use those to make comparisons between candidates unless the numbers are small. We need percentages!

First, we'll import a dataset of county-level gubernatorial results from Maryland's 2022 general election that is in the data folder in this chapter's pre-lab directory. We'll use this to explore ways to create new information from existing data.

**Task**

```{r}
general_22 <- read_csv('data/md_gov_county.csv')
```

Let's add a column called `percent_moore` for the percentage of votes that went to Wes Moore, the Democratic candidate who won the election, in each county. The code to calculate a percentage is pretty simple. Remember, with `summarize`, we used `n()` to count things. With `mutate`, we use very similar syntax to calculate a new value -- a new column of data -- using other values in our dataset.

To calculate a percentage, we need both the number of votes for Moore but also the total number of votes. We'll use mutate to create both columns. The first will be total votes, and the second will be the percentage for Moore. The key here is to save the dataframe to itself so that our changes stick.

**Task** Let's add a new column based on an existing column. Run the following code to create a new column called `total_votes` based on the votes cast for each candidate, and then to create a new column called

```{r}
general_22 <- general_22 |>
  mutate(
    total_votes = cox + moore + lashar + wallace + write_ins,
    pct_moore = moore/total_votes
  )
```

Describe what you think this code is doing below.

**Answer**

### Task 11: Better percentage calculation

**Task** Run the following code to make our new column called `pct_moore` show a percentage instead of a decimal.

```{r}
# make it a percentage
general_22 <- general_22 |>
  mutate(
    pct_moore = (moore/total_votes)*100
  )
```

### Task 12: Mutate with ordering

**Task** Run the following code to order by our new column.

```{r}
# better ordering?
general_22 <- general_22 |>
  mutate(
    pct_moore = (moore/total_votes)*100
  ) |> 
  arrange(desc(pct_moore))
```

How did the answer change from the previous task, and why?

**Answer**

### Task 13: Mutate with ordering, part 2

**Task** Run the following code to order by our new column, but in ascending order

```{r}
# better ordering ?
general_22 |>
  arrange(pct_moore)
```

Is this a more interesting or useful answer? Why?

**Answer**

### Task 14: Standardize existing data using mutate

Mutate is also useful for standardizing data - for example, making different spellings of, say, campaign spending recipients.

Let's load some Maryland state campaign expenditures into a `maryland_expenses` dataframe, and focus in particular on the `payee_name` column.

```{r}
maryland_expenses <- read_csv("data/maryland_expenses.csv")
maryland_expenses
```

You'll notice that there's a mix of styles: lower-case and upper-case names like "Anedot" and "ANEDOT", for example. R will think those are two different payees, and that will mean that any aggregates we create based on payee_name won't be accurate.

So how can we fix that? Mutate - it's not just for math! And a function called `str_to_upper` that will convert a character column into all uppercase.

**Task** Run the following code:

```{r}
standardized_maryland_expenses <- maryland_expenses |>
  mutate(
    payee_upper = str_to_upper(payee_name)
)
```

**Task** Search the Internet for tidyverse functions similar to str_to_upper. Name at least two and describe what they do. If you use ChatGPT for this, include the question you submitted.

**Answer**

There are lots of potential uses for standardization - addresses, zip codes, anything that can be misspelled or abbreviated.

### Task 15: Create a new column using case_when

Mutate is even more useful when combined with some additional functions. Let's keep rolling with our expenditure data. Take a look at the address column: it contains a full address, including the state, spelled out. It would be useful to have a separate `state` column with an abbreviation. We can check to see if a state name is contained in that column and then populate a new column with the value we want, using the functions `str_detect` and `case_when`. We can identify the state by the following pattern: a space, followed by the full name, followed by another space. So, " Maryland ". The `case_when` function handles multiple variations, such as if the state is Maryland or the state is Texas, etc. Crucially, we can tell R to populate the new column with `NA` if it doesn't find a match.

**Task** Run the following code and look at the output. Then write a sentence or two describing what you think the mutate statement is doing step by step.

**Answer**

```{r}
maryland_expenses_with_state <- maryland_expenses |>
  mutate(
    state = case_when(
        str_detect(address, " Maryland ") ~ "MD",
        str_detect(address, " California ") ~ "CA",
        str_detect(address, " Washington ") ~ "WA",
        str_detect(address, " Louisiana ") ~ "LA",
        str_detect(address, " Florida ") ~ "FL",
        str_detect(address, " North Carolina ") ~ "NC",
        str_detect(address, " Massachusetts ") ~ "MA",
        str_detect(address, " West Virginia ") ~ "WV",
        str_detect(address, " Virginia ") ~ "VA",
        .default = NA
      )
  )
```

There's a lot going on here, so let's unpack it. It starts out as a typical mutate statement, but `case_when` introduces some new things. Each line checks to see if the pattern is contained in the address column, followed by `~` and then a value for the new column for records that match that check. You can read it like this: "If we find ' Maryland ' in the address column, then put 'MD' in the state column" for Maryland and then a handful of states, and if we don't match any state we're looking for, make state `NA`.

We can then use our new `state` column in group_by statements to make summarizing easier.

**Task** Run the following code.

```{r}
maryland_expenses_with_state |>
  group_by(state) |>
  summarize(total = sum(amount)) |>
  arrange(desc(total))
```

Does this answer make sense to you? Why or why not?

**Answer**

Mutate is there to make your data more useful and to make it easier for you to ask more and better questions of it.

### Task 16: More questions

Now that you have seen how to use mutate, filtering and dates, give me three questions about either the UMD course data or the Maryland expenditure data that you could ask that would make use of some or all of those new functions. They can be better versions of the questions from the previous pre-lab.

**Answer**

1.  

2.  

3.  
