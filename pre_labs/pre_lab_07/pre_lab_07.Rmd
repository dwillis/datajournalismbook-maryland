---
title: "pre_lab_07.Rmd"
author: "derek willis"
date: "2023-03-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Task 1: Load libraries and settings

**Task** Run the following code in the gray-colored codeblock below to load the tidyverse library and the tidycensus library (remove the comment in front of install.packages if you need to install the latter)

```{r}
# turn off sci notation
options(scipen=999)
library(tidyverse)
# if needed, install tidycensus, then load it.
# install.packages("tidycensus")
library(tidycensus)
```

# Intro to APIs: The Census

We're going to use a library called `tidycensus` which makes calls to the Census API in a very tidy way, and gives you back tidy data. That means we don't have to go through the process of importing the data from a file. I can't tell you how amazing this is, speaking from experience.

To use the API, you need to [an API key from the Census Bureau](https://api.census.gov/data/key_signup.html). It takes a few minutes and you need to activate your key via email. Once you have your key, you need to set that for this session. Just FYI: Your key is your key. Do not share it.

### Task 2: Sign up for an API Key and set it

**Task** Replace YOUR KEY HERE in the codeblock below with your Census API Key (leave the quotemarks).

```{r echo=FALSE}
#census_api_key("YOUR KEY HERE", install=TRUE)
```

The `install=TRUE` part saves your key for future use.

So to give you some idea of how complicated the data is, let's pull up just one file from the decennial Census. We'll use Summary File 1, or SF1. That has the major population and housing stuff.

### Task 3: Examining Census data

**Task** Run the following codeblock and look at the resulting variable.

```{r}
sf1 <- load_variables(2010, "sf1", cache = TRUE)
View(sf1)
```

Note: There are thousands of variables in SF1. That's not a typo. Open it in your environment by double clicking. As you scroll down, you'll get an idea of what you've got to choose from.

The `name` variable is the Census code for each kind of data, while `label` describes it and `concept` is a broader category.

If you think that's crazy, try the SF3 file from 2000.

**Task** Run the following codeblock and look at the resulting variable.

```{r}
sf3 <- load_variables(2000, "sf3", cache = TRUE)
```

### Task 4: Calculate the fastest-growing state

So let's try to answer a question using the Census. What is the fastest growing state since 2000?

To answer this, we need to pull the total population by state in each of the decennial census.

**Task** Run the following codeblock and examine the 2010 results

```{r}
p00 <- get_decennial(geography = "state", variables = "P001001", year = 2000)
p10 <- get_decennial(geography = "state", variables = "P001001", year = 2010)
```

Let's take a peek at 2010.

```{r}
p10
```

As you can see, we have a GEOID, NAME, then variable and value. Variable and value are going to be the same. Because those are named the same thing, to merge them together, we need to rename them. Remember how we used `rename` in the last lab? We're going to use it some more.

**Task** Run the following codeblock to rename the population total columns in each dataframe:

```{r}
p10 |> select(GEOID, NAME, value) |> rename(Population2010=value) -> p10

p00 |> select(GEOID, NAME, value) |> rename(Population2000=value) -> p00
```

Now we join the data together.

**Task** Run the following codeblock to combine the two dataframes into a single variable called `alldata`:

```{r}
alldata <- p00 |> inner_join(p10)
```

And now we calculate the percent change.

**Task** Run the following codeblock to calculate the percentage change and put the state with the largest percentage growth below. **Answer**

```{r}
alldata |> mutate(change = ((Population2010-Population2000)/Population2000)*100) |> arrange(desc(change))
```

You may be asking: hey, wasn't there a 2020 Census? Where's that data? The answer is that it's coming - the Census Bureau has a [schedule of releases](https://www.census.gov/programs-surveys/popest/about/schedule.html). There are some variables available:

```{r}
pl <- load_variables(2020, "pl")
View(pl)
```

## The ACS

In 2010, the Census Bureau replaced SF3 with the American Community Survey. The Good News is that the data would be updated on a rolling basis. The bad news is that it's more complicated because it's more like survey data with a large sample. That means there's margins of error and confidence intervals to worry about.

What is Maryland's richest county?

We can measure this by median household income. That variable is `B19013_001`, so we can get that data like this (I'm narrowing it to the top 20 for simplicity):

### Task 5: Answer Questions with ACS Data

**Task** Run the following codeblock to find the Maryland county with the highest median household income and put the answer below. **Answer**

```{r}
md <- get_acs(geography = "county",
              variables = c(medincome = "B19013_001"),
              state = "MD",
              year = 2021)

md <- md |> arrange(desc(estimate)) |> top_n(20, estimate)

md
```

What do the top counties all have in common? Lots of suburban flight from D.C and Baltimore. But do the margins of error let us say one county is richer than the other? We can find this out visually using error bars. Don't worry much about the code here -- we'll cover that soon enough.

### Task 6: Margins of Error

**Task** Run the following codeblock to create a chart showing the margin of error for each county. The current headline isn't very descriptive of the data. What should it be? **Answer**

```{r}
md |>
  mutate(NAME = gsub(" County, Maryland", "", NAME)) |>
  ggplot(aes(x = estimate, y = reorder(NAME, estimate))) +
  geom_errorbarh(aes(xmin = estimate - moe, xmax = estimate + moe)) +
  geom_point(color = "red") +
  labs(title = "Household income by county in Maryland",
       subtitle = "2017-2021 American Community Survey",
       y = "",
       x = "ACS estimate (bars represent margin of error)")
```

As you can see, some of the error bars are quite wide. Some are narrow. But if the bars overlap, it means the difference between the two counties is within the margin of error, and the differences aren't statistically significant.

Is the difference between Calvert and Montgomery significant? **Answer**

Is the difference between Howard and everyone else significant? **Answer**

### Task 7: Joining Multiple Years Together

Let's ask another question of the ACS -- did any counties lose income from the time of the global financial crisis to the current 5-year window?

Let's re-label our first household income data.

**Task** Run the following codeblock to retrieve Maryland county median income from 2010 and from 2021.

```{r}
md21 <- get_acs(geography = "county",
              variables = c(medincome = "B19013_001"),
              state = "MD",
              year = 2021)

md10 <- get_acs(geography = "county",
              variables = c(medincome = "B19013_001"),
              state = "MD",
              year = 2010)
```

What we're going to do next is a lot, but each step is simple. We're going to join the data together, so each county has one line of data. Then we're going to rename some fields that repeat. Then we're going to calculate the minimum and maximum value of the estimate using the margin of error. That'll help us later. After that, we're going to calculate a percent change and sort it by that change.

**Task** Run the following codeblock to join the data, rename the population estimates and then calculate the values we need. Notice how we select *after* we do the initial calculations so we only see the columns we're interested in (and drop the ones we don't want to see). Also note how the select function has the minus sign (-) in front of some columns? That means we don't want to see them in our result. Which jurisdictions saw the largest increases in median income? Did any counties see their median incomes fall from 2010-2021? **Answer**

```{r}
md10 |>
  # join md10 to md21 using the shared GEOID and NAME columns
  inner_join(md21, by=c("GEOID", "NAME")) |>
  # rename the first estimate to clarify that it's from 2010 and the second estimate to clarify that it's from 2021
  rename(estimate2010=estimate.x, estimate2021=estimate.y) |>
  mutate(min2010 = estimate2010-moe.x, max2010 = estimate2010+moe.x, min2020 = estimate2021-moe.y, max2021 = estimate2021+moe.y) |>
  select(-variable.x, -variable.y, -moe.x, -moe.y) |>
  mutate(change = ((estimate2021-estimate2010)/estimate2010)*100) |>
  arrange(desc(change))
```

### Task 8: Combine with Maryland Data

Combining Census data with other types of data really unlocks its power for journalism. In this case, we'll use some 2019-20 data from Maryland high schools, including the number of graduates and the number of students who enrolled in college the next fall semester, plus the percentage. We also have the zip code of the high school, which will enable us to bring in Census data.

**Task** Run the following codeblock to load the CSV file and make sure the zip code is a character column, because that's what we'll need to join.

```{r}
md_high_schools <- read_csv("data/md_high_schools.csv") |>
  mutate(zip = as.character(zip))
```

The Census Bureau has Zip Code Tabulation Areas - they are mostly identical to what we know as zip codes, with some small differences. In most cases we can use them interchangeably.

**Task** Let's get ZCTA household income data from the ACS using tidycensus for each zip code in `md_high_schools`. Run the following codeblock to retrieve household income data from 2019 - the latest year for which we have it for all Maryland ZCTAs - first, then join them to `md_high_schools` using the GEOID column. We'll also create min and max values and drop any rows where we don't have income estimates. What's one question we could ask of this data now that we have enrollment percentages and household income for the high school's zip code? What might make the answer harder to interpret? **Answer**

```{r}
md_zipcodes <- get_acs(geography="zcta", variables = "B19013_001", state='MD', year=2019)
md_high_schools_with_acs <- md_high_schools |> left_join(md_zipcodes, by=c('zip'='GEOID'))
md_high_schools_with_acs <- md_high_schools_with_acs |> mutate(min=(estimate-moe), max=(estimate+moe)) |> drop_na()
```

**Task** Let's look at the average household income for high schools that have 60% or more graduates immediately enrolling in college, and then look at those with less than 40%. Write a sentence describing the results. **Answer**

```{r}
md_high_schools_with_acs |>
  filter(percent_of_high_school_graduates_enrolled >= 60) |> 
  summarize(avg_income = mean(estimate), count =n())

md_high_schools_with_acs |>
  filter(percent_of_high_school_graduates_enrolled <= 40) |> 
  summarize(avg_income = mean(estimate), count = n())
```

**Task** What is another question you could ask of this data? **Answer**
